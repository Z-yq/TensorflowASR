
speech_config:
  use_mel_layer: True
  mel_layer_type: Melspectrogram #Spectrogram
  trainable_kernel: False #support train model
  sample_rate: 16000
  frame_ms: 25
  stride_ms: 10
  delta: False
  delta_delta: False
  pitch: False
  num_feature_bins: 80
  feature_type: logfbank
  preemphasis: 0.97
  normalize_signal: True
  normalize_feature: True
  normalize_per_feature: False
  reduction_factor: 4 #should keep the same with model_config, DS2 : time_reduction_factor *= s[0] for s in 'conv_strides'
  train_list: './test_list.txt'
  eval_list: './am_eval_list.txt'
  wav_max_duration: 7 # s
  only_chinese: True



decoder_config:
  vocabulary: './AMmodel/am_tokens.txt'
  blank_at_zero: False
  beam_width: 1


augments_config:
  noise:
    active: False
    sample_rate: 16000
    SNR: [0,15]
    noises: './noise'
  masking:
    active: True
    zone: (0.1,0.9)
    mask_ratio: 0.3
    mask_with_noise: True

  pitch:
    active: True
    zone: (0.0,1.0)
    sample_rate: 16000
    factor: (-1,3)

  speed:
    active: True
    factor: (0.5,2)

learning_config:

  optimizer_config:
    warmup_steps: 10000
    beta1: 0.9
    beta2: 0.98
    epsilon: 1e-9

  running_config:
    batch_size: 4
    train_steps_per_batches: 10
    eval_steps_per_batches: 10
    num_epochs: 2
    outdir: './deepspeech2-logs'
    log_interval_steps: 300
    eval_interval_steps: 500
    save_interval_steps: 500
    guide_attention: True #for LAS
  redis_config:
    use_redis: False
    redis_ip: '1.127.0.1'
    redis_port: 6379
    data_name: 'data'
    data_dict_key: ['feature','wavs','input_length','label','label_length']

